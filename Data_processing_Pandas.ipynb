{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becoming-findings",
   "metadata": {},
   "source": [
    "# Data Processing in Python using Pandas\n",
    "\n",
    "\n",
    "---\n",
    "**author**:\n",
    "  - **Nader Tavana**\n",
    "\n",
    "---\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-cycle",
   "metadata": {},
   "source": [
    "### Import libraries, reading data and database connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charitable-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import sqlite3\n",
    "import tempfile\n",
    "\n",
    "\n",
    "\n",
    "baza = os.path.join(tempfile.mkdtemp(), 'example.db')\n",
    "if os.path.isfile(baza):\n",
    "   os.remove(baza)\n",
    "\n",
    "\n",
    "\n",
    "Tags = pd.read_csv(\"travel_stackexchange_com/Tags.csv.gz\",compression = \"gzip\")\n",
    "Badges = pd.read_csv(\"travel_stackexchange_com/Badges.csv.gz\",compression = \"gzip\")\n",
    "Comments = pd.read_csv(\"travel_stackexchange_com/Comments.csv.gz\",compression = \"gzip\")\n",
    "Posts = pd.read_csv(\"travel_stackexchange_com/Posts.csv.gz\",compression = \"gzip\")\n",
    "PostLinks = pd.read_csv(\"travel_stackexchange_com/PostLinks.csv.gz\",compression = \"gzip\")\n",
    "Users = pd.read_csv(\"travel_stackexchange_com/Users.csv.gz\",compression = \"gzip\")\n",
    "Votes = pd.read_csv(\"travel_stackexchange_com/Votes.csv.gz\",compression = \"gzip\")\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(baza) # create the connection\n",
    "Badges.to_sql(\"Badges\", conn) # import the data frame into the database\n",
    "Comments.to_sql(\"Comments\", conn)\n",
    "PostLinks.to_sql(\"PostLinks\", conn)\n",
    "Posts.to_sql(\"Posts\", conn)\n",
    "Tags.to_sql(\"Tags\", conn)\n",
    "Users.to_sql(\"Users\", conn)\n",
    "Votes.to_sql(\"Votes\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-completion",
   "metadata": {},
   "source": [
    "### SQL queries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-intersection",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "present-package",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# query 1\n",
    "query1=pd.read_sql_query(\"\"\"\n",
    "SELECT Posts.Title, RelatedTab.NumLinks\n",
    "FROM\n",
    "(SELECT RelatedPostId AS PostId, COUNT(*) AS NumLinks\n",
    "FROM PostLinks\n",
    "GROUP BY RelatedPostId) AS RelatedTab\n",
    "JOIN Posts ON RelatedTab.PostId=Posts.Id\n",
    "WHERE Posts.PostTypeId=1\n",
    "ORDER BY NumLinks DESC\n",
    "\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "# solution 1 \n",
    "def solution1():\n",
    "    \n",
    "    df=PostLinks.groupby(['RelatedPostId']).size().reset_index(name='NumLinks') #group by RelatedPostId,COUNT(*) \n",
    "\n",
    "    RelatedTab=df.rename(columns={\"RelatedPostId\": \"PostId\"})    # AS NumLinks               \n",
    "\n",
    "    df2=pd.merge(RelatedTab,Posts,how='inner',left_on='PostId',right_on='Id') #JOIN Posts ON RelatedTab.PostId=Posts.Id\n",
    "    \n",
    "    RelatedTab_Posts=df2[df2['PostTypeId']==1] # WHERE Posts.PostTypeId=1\n",
    "\n",
    "    RelatedTab_Posts=RelatedTab_Posts.sort_values('NumLinks',ascending=False) #ORDER BY NumLinks DESC\n",
    "\n",
    "    \n",
    "    RelatedTab_Posts=RelatedTab_Posts[['Title','NumLinks']] #SELECT Posts.Title, RelatedTab.NumLinks\n",
    "\n",
    "    RelatedTab_Posts=RelatedTab_Posts.sort_values('Title') # here we have to sort title because some titles have same NumLinks\n",
    "                                                           # value so for comparison it gives us error\n",
    "    \n",
    "    RelatedTab_Posts=RelatedTab_Posts.reset_index(drop=True) # reser index for comparison\n",
    "    return RelatedTab_Posts\n",
    "\n",
    "query1=query1.sort_values('Title') # # here we have to sort title because some titles have same NumLinks\n",
    "                                                           # value so for comparison it gives us error\n",
    "query1=query1.reset_index(drop=True) # reset index for comparison\n",
    "\n",
    "solution1=solution1()\n",
    "\n",
    "print(solution1.equals(query1)) # check equality\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-entrance",
   "metadata": {},
   "source": [
    "### 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "endangered-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# query 2\n",
    "query2=pd.read_sql_query(\"\"\"\n",
    "SELECT\n",
    "    Users.DisplayName,\n",
    "    Users.Age,\n",
    "    Users.Location,\n",
    "    SUM(Posts.FavoriteCount) AS FavoriteTotal,\n",
    "    Posts.Title AS MostFavoriteQuestion,\n",
    "    MAX(Posts.FavoriteCount) AS MostFavoriteQuestionLikes\n",
    "FROM Posts\n",
    "JOIN Users ON Users.Id=Posts.OwnerUserId\n",
    "WHERE Posts.PostTypeId=1\n",
    "GROUP BY OwnerUserId\n",
    "ORDER BY FavoriteTotal DESC\n",
    "LIMIT 10\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "# solution 2\n",
    "def solution2():\n",
    "    \n",
    "    # Firstly I join the Users and Posts data frames\n",
    "    join = pd.merge(Users, Posts[Posts['PostTypeId'] == 1], left_on = 'Id', right_on = 'OwnerUserId')\n",
    "\n",
    "    # I apply the SUM() and MAX() functions on the merged data frames\n",
    "    group = join.groupby('OwnerUserId').agg({'FavoriteCount': [np.sum, np.max]}).reset_index()\n",
    "    group.columns = group.columns.get_level_values(0)\n",
    "    group.columns = ['OwnerUserId', 'FavoriteTotal', 'FavoriteMax']\n",
    "\n",
    "    # Since I lost some columns while applying SUM() and MAX() I join the aggregated data frame with merged Posts and Users\n",
    "    answer = pd.merge(group, join, left_on = ['OwnerUserId', 'FavoriteMax'],\n",
    "                      right_on = ['OwnerUserId', 'FavoriteCount'], how = 'left')\n",
    "\n",
    "    # Now I have all the needed columns, I just have to select the right ones and order the rows\n",
    "    answer = answer[['DisplayName', 'Age', 'Location', 'FavoriteTotal', 'Title', 'FavoriteMax']]\n",
    "    answer = answer.rename(columns = {'Title': 'MostFavoriteQuestion', 'FavoriteMax': 'MostFavoriteQuestionLikes'})\n",
    "    answer = answer.sort_values(by = 'FavoriteTotal', ascending = False).reset_index(drop = True).head(10)\n",
    "    return answer\n",
    "\n",
    "solution2=solution2()\n",
    "\n",
    "print(solution2.equals(query2)) # check equality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-bulgarian",
   "metadata": {},
   "source": [
    "### Comments on 2nd query: \n",
    "Firstly calculating the FavoriteTotal and MostFavoriteQuestionLikes. Then we could use column OwnerUserId combined with MostFavoriteQuestion likes to merge the aggregated data with Users and Posts, regaining all the variables lost while aggregating. Then selecting the right columns and order the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-accuracy",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "armed-philip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "query3=pd.read_sql_query(\"\"\"\n",
    "\n",
    "SELECT\n",
    "Posts.Title,\n",
    "CmtTotScr.CommentsTotalScore\n",
    "FROM (\n",
    "SELECT\n",
    "PostID,\n",
    "UserID,\n",
    "SUM(Score) AS CommentsTotalScore\n",
    "FROM Comments\n",
    "GROUP BY PostID, UserID\n",
    ") AS CmtTotScr\n",
    "JOIN Posts ON Posts.ID=CmtTotScr.PostID AND Posts.OwnerUserId=CmtTotScr.UserID\n",
    "WHERE Posts.PostTypeId=1\n",
    "ORDER BY CmtTotScr.CommentsTotalScore DESC\n",
    "LIMIT 10\n",
    "\n",
    "\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "def solution3():\n",
    "    df=Comments.groupby(['PostId','UserId'])['Score'].sum().reset_index() # SUM(Score) AS CommentsTotalScore\n",
    "    CmtTotScr=df.rename(columns={\"Score\": \"CommentsTotalScore\"})          # GROUP BY PostID, UserID\n",
    "     \n",
    "    # JOIN Posts ON Posts.ID=CmtTotScr.PostID AND Posts.OwnerUserId=CmtTotScr.UserID\n",
    "    Posts_CmtTotScr=pd.merge(CmtTotScr,Posts,how='inner',left_on=['PostId','UserId'],right_on=['Id','OwnerUserId'])\n",
    "\n",
    "    Posts_CmtTotScr=Posts_CmtTotScr[Posts_CmtTotScr['PostTypeId']==1] # WHERE Posts.PostTypeId=1\n",
    "    \n",
    "    Posts_CmtTotScr=Posts_CmtTotScr.sort_values('CommentsTotalScore',ascending=False) # ORDER BY CmtTotScr.CommentsTotalScore DESC\n",
    "    \n",
    "    Posts_CmtTotScr=Posts_CmtTotScr[['Title','CommentsTotalScore']] # Posts.Title,CmtTotScr.CommentsTotalScore\n",
    "\n",
    "    Posts_CmtTotScr=Posts_CmtTotScr.head(10) # LIMIT 10\n",
    "    \n",
    "    # We need to sort based on title also because some titles have same CommentsTotalScore hence for comparison we need to sort it\n",
    "    Posts_CmtTotScr=Posts_CmtTotScr.sort_values(['CommentsTotalScore', 'Title'], ascending=[False, True]) \n",
    "    \n",
    "    Posts_CmtTotScr=Posts_CmtTotScr.reset_index(drop=True) # reset index for comparison\n",
    "    \n",
    "    return Posts_CmtTotScr\n",
    "\n",
    "\n",
    "# # We need to sort based on title also because some titles have same CommentsTotalScore hence for comparison we need to sort it\n",
    "query3=query3.sort_values(['CommentsTotalScore', 'Title'], ascending=[False, True]) \n",
    "\n",
    "query3=query3.reset_index(drop=True) # reset index for comparison\n",
    "\n",
    "solution3=solution3()\n",
    "\n",
    "print(solution3.equals(query3)) # check for equality\n",
    "\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
